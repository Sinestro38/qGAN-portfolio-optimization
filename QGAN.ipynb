{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wires = range(15)\n",
    "dev = qml.device('default.qubit', wires=wires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/prices_15_4.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_data = data[0]\n",
    "msft_b = msft_data[0]\n",
    "msft_f = msft_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_one_axis(data):\n",
    "    in_one_arr = []\n",
    "    for i in range(19):\n",
    "        if i <= 14:\n",
    "            in_one_arr.append(data[0][i])\n",
    "        elif i >=15:\n",
    "            in_one_arr.append(data[1][i-15])\n",
    "    return np.reshape(in_one_arr, (1,1,19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of QGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ansatz(w):\n",
    "    qml.broadcast(unitary=qml.RY, pattern = 'single', wires = wires, parameters = w[0:15])\n",
    "    for k in range(1, int(len(w)) // 15):\n",
    "        qml.broadcast(unitary=qml.CZ, pattern = 'ring', wires=wires)\n",
    "        qml.broadcast(unitary=qml.RY, pattern = 'single', wires = wires, parameters = w[(15*k):(15*(k+1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface=\"tf\")\n",
    "def gen_circuit(b_seq, gen_weights):\n",
    "    qml.templates.AngleEmbedding(b_seq, wires, rotation='X')\n",
    "    gen_ansatz(gen_weights)\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(equity_data, gen_weights):\n",
    "    generated_prices =  gen_circuit(equity_data[0], gen_weights).numpy()\n",
    "    return [equity_data[0], gen_circuit(equity_data[0], gen_weights).numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_gen_weights = np.random.normal(size=(15,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(15,) dtype=float64, numpy=\n",
       "array([-0.12884513, -0.01361892,  0.86088683, -1.04190869, -1.13304563,\n",
       "       -0.07415381,  0.32951867,  0.32369006,  0.17095212,  0.07537326,\n",
       "       -2.04152151,  1.29285969, -0.34701718,  0.41861991,  0.59777649])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable(init_gen_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.        ,  0.68858394, -0.71996818,  0.64508565,  0.12111897,\n",
       "         0.84157581,  0.8777076 ,  0.22345133, -0.30409296, -0.18410706,\n",
       "         0.        , -0.8391851 ,  0.06801392,  0.02368372,  0.0141945 ]),\n",
       " array([0.53582371, 0.77207501, 0.49001443, 0.4031784 ])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(msft_data, init_gen_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testing function to retrieve gradients from generator\"\"\"\n",
    "def gen_grad(data, w):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = gen_circuit(msft_data[0], w)\n",
    "    gen_gradient = tape.gradient(loss, w)\n",
    "    print(w.numpy(), gen_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12884513 -0.01361892  0.86088683 -1.04190869 -1.13304563 -0.07415381\n",
      "  0.32951867  0.32369006  0.17095212  0.07537326 -2.04152151  1.29285969\n",
      " -0.34701718  0.41861991  0.59777649] tf.Tensor(\n",
      "[ 0.06942287  0.01051548 -0.57020106  0.68987341  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ], shape=(15,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "gen_grad(msft_data, tf.Variable(init_gen_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discrim():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=1, activation='relu', input_shape=[1, 19]))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, 1, 16)             320       \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 1, 16)             272       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1, 128)            2176      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1, 1)              129       \n",
      "=================================================================\n",
      "Total params: 2,897\n",
      "Trainable params: 2,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discrim()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pennylane construction of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_real_true(equity_data):\n",
    "    equity_data_in_one_dim = reshape_to_one_axis(equity_data)\n",
    "    confidence = discriminator(equity_data_in_one_dim).numpy()[0][0][0]\n",
    "    prob_real_true = (confidence + 1)/ 2\n",
    "    return prob_real_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_fake_true(equity_data, gen_weights):\n",
    "    gen_data = [equity_data[0], gen_circuit(equity_data[0], gen_weights).numpy()]\n",
    "    gen_data_in_one_dim = reshape_to_one_axis(gen_data)\n",
    "    confidence = discriminator(gen_data_in_one_dim).numpy()[0][0][0]\n",
    "    prob_fake_true = (confidence + 1)/ 2\n",
    "    return prob_fake_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7634900510311127\n",
      "0.7557262778282166\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test\"\"\"\n",
    "genn = generator(data[2], init_gen_weights)\n",
    "print(prob_fake_true(genn, init_gen_weights))\n",
    "print(prob_real_true(data[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_cost(gen_weights):\n",
    "    return -prob_fake_true(msft_data, gen_weights)\n",
    "\n",
    "def disc_cost():\n",
    "    cost = prob_fake_true(msft_data, gen_weights) - prob_real_true(msft_data)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this block go bad\n"
     ]
    }
   ],
   "source": [
    "gen_weights = init_gen_weights\n",
    "try:\n",
    "    with tf.GradientTape() as tape:\n",
    "        gen_cost = gen_cost(gen_weights)\n",
    "    print(tape.gradient(gen_cost, gen_weights))\n",
    "except:\n",
    "    print(\"this block go bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss â€” real is 1, fake is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    \"\"\"Calculating loss\"\"\"\n",
    "    return cross_entropy(np.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(fake_output, real_output):    \n",
    "    \"\"\"Compute discriminator loss.\"\"\" \n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256\n",
    "\n",
    "\n",
    "def train_step(equity_data, gen_weights):\n",
    "    \"\"\"Run train step on provided image batch.\"\"\"\n",
    "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape: \n",
    "        generated_prices = [equity_data[0], gen_circuit(equity_data[0], gen_weights)] \n",
    "        \n",
    "        \"\"\"Reshaping equity arrays to feed into discrim\"\"\"\n",
    "        gen_prices_in_one_arr = reshape_to_one_axis(generated_prices)\n",
    "        real_prices_in_one_arr = reshape_to_one_axis(equity_data)\n",
    "\n",
    "        \"\"\"Getting outputs from discrim\"\"\"\n",
    "        real_output = discriminator(real_prices_in_one_arr)\n",
    "        fake_output = discriminator(gen_prices_in_one_arr)\n",
    "\n",
    "        \"\"\"Calculating loss\"\"\"\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, gen_weights)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    print(gradients_of_generator)\n",
    "#     generator_optimizer.apply_gradients(\n",
    "#         zip(gradients_of_generator, gen_weights))\n",
    "#     discriminator_optimizer.apply_gradients(\n",
    "#         zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.7042643>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3934547>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step(msft_data, tf.Variable(init_gen_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing new pipeline with just f_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_disc():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=1, activation='relu', input_shape=[1, 4]))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 1, 16)             80        \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 1, 16)             272       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1, 128)            2176      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1, 1)              129       \n",
      "=================================================================\n",
      "Total params: 2,657\n",
      "Trainable params: 2,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "small_disc = make_disc()\n",
    "small_disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer sequential_12 is incompatible with the layer: : expected min_ndim=3, found ndim=1. Full shape received: (4,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-601e0cf07a7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msmall_disc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_circuit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsft_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_gen_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\qiskit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qiskit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    232\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    235\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                          \u001b[1;34m': expected min_ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer sequential_12 is incompatible with the layer: : expected min_ndim=3, found ndim=1. Full shape received: (4,)"
     ]
    }
   ],
   "source": [
    "small_disc(gen_circuit(msft_data[0], init_gen_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256\n",
    "\n",
    "\n",
    "def train_step(equity_data, gen_weights):\n",
    "    \"\"\"Run train step on provided image batch.\"\"\"\n",
    "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape: \n",
    "        generated_prices = gen_circuit(equity_data[0], gen_weights)\n",
    "        \n",
    "\n",
    "        \"\"\"Getting outputs from discrim\"\"\"\n",
    "        real_output = discriminator(real_prices_in_one_arr)\n",
    "        fake_output = discriminator(gen_prices_in_one_arr)\n",
    "\n",
    "        \"\"\"Calculating loss\"\"\"\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "#     with tf.GradientTape() as gen_tape:\n",
    "#         f_seq = gen_circuit(equity_data[0], gen_weights)\n",
    "#         generated_prices = [equity_data[0], f_seq]\n",
    "#         loss = generator_loss(discriminator(reshape_to_one_axis(generated_prices)))\n",
    "#     gen_gradient = gen_tape.gradient(f_seq, gen_weights)\n",
    "    \n",
    "#     print(gen_gradient)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, gen_weights)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    print(gradients_of_generator)\n",
    "#     generator_optimizer.apply_gradients(\n",
    "#         zip(gradients_of_generator, gen_weights))\n",
    "#     discriminator_optimizer.apply_gradients(\n",
    "#         zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.61227745>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3528016>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step(msft_data, tf.Variable(init_gen_weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
